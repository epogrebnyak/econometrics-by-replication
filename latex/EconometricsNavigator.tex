%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{0}



\title{Econometrics Navigator Documentation}
\date{Nov 10, 2019}
\release{0.0.5}
\author{Evgeny Pogrebnyak}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Analysis of variance (ANOVA)}
\label{\detokenize{topics/anova:analysis-of-variance-anova}}\label{\detokenize{topics/anova::doc}}\begin{itemize}
\item {} 
ANOVA can mean several things: actual decomposition of variance, comparing the group means or representation of regression results

\item {} 
Boils down to a regression with dummy (categorical) variables

\item {} 
Heavy traction in terminolgy from design of exepriments (see definitons section \sphinxhref{https://en.wikipedia.org/wiki/Analysis\_of\_variance}{here})

\item {} 
Standartised result tables with \sphinxcode{\sphinxupquote{SS}}, \sphinxcode{\sphinxupquote{DF}}, \sphinxcode{\sphinxupquote{MSS}}, \sphinxcode{\sphinxupquote{F}}, \sphinxcode{\sphinxupquote{p}}

\item {} 
Frightening multitude of R packages

\item {} 
May want to look at \sphinxhref{https://www.itl.nist.gov/div898/strd/anova/SiRstv.html}{a simple reference case}

\end{itemize}

Quote:
\begin{quote}

\sphinxstyleemphasis{ANOVA can be seen as “syntactic sugar” for a special subgroup of linear regression models. ANOVA is regularly used by researchers who are not statisticians by training. They are now “institutionalized” and its hard to convert them back to using the more general representation} \sphinxhref{https://stats.stackexchange.com/users/1307/suncoolsu}{suncoolsu}
\end{quote}


\section{Code examples}
\label{\detokenize{topics/anova:code-examples}}\begin{itemize}
\item {} 
\sphinxurl{https://stackoverflow.com/questions/25537399/anova-in-python-using-pandas-dataframe-with-statsmodels-or-scipy}

\item {} 
\sphinxurl{http://www.statsmodels.org/devel/anova.html}

\item {} 
\sphinxurl{https://stats.stackexchange.com/a/175265/211794}

\item {} 
also possibly in Think Stats and \sphinxhref{https://stats.stackexchange.com/a/5283/211794}{Hadley Wickham}

\end{itemize}


\section{Links}
\label{\detokenize{topics/anova:links}}
Intro by \sphinxhref{http://statisticsbyjim.com/anova/}{Jim}

Cross-Validated has several general discussions:
\begin{itemize}
\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/555/why-is-anova-taught-used-as-if-it-is-a-different-research-methodology-compared}{why-is-anova-taught-used-as-if-it-is-a-different-research-methodology-compared}

\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/5278/how-to-visualize-what-anova-does}{how-to-visualize-what-anova-does}

\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/12398/how-to-interpret-f-and-p-value-in-anova}{how-to-interpret-f-and-p-value-in-anova}

\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/2730/good-resource-to-understand-anova-and-ancova}{good-resource-to-understand-anova-and-ancova}

\end{itemize}

… followed by ANOVA vs regression:
\begin{itemize}
\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/34616/difference-between-regression-analysis-and-analysis-of-variance}{difference-between-regression-analysis-and-analysis-of-variance}

\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/175246/why-is-anova-equivalent-to-linear-regression}{why-is-anova-equivalent-to-linear-regression}

\end{itemize}

NIST Handbook deals with ANOVA assumptions and interepations, as well as provides reference datasets:
\begin{itemize}
\item {} 
\sphinxhref{https://www.itl.nist.gov/div898/handbook/prc/section4/prc432.htm}{The one-way ANOVA model and assumptions}

\item {} 
\sphinxhref{https://www.itl.nist.gov/div898/handbook/prc/section4/prc433.htm}{Interpretation of the ANOVA table}

\item {} 
\sphinxhref{https://www.itl.nist.gov/div898/strd/anova/anova.html}{Reference datasets and regresion results}

\end{itemize}

Very simple and illustrative case NIST reference case \sphinxhref{https://www.itl.nist.gov/div898/strd/anova/SiRstv.html}{here}.

Comoact Julia package \sphinxhref{https://github.com/marcpabst/ANOVA.jl}{ANOVA.jl} at about 150 lines of code, but not as much documentation yet.

ANOVA is again a case where \sphinxhref{https://ru.wikipedia.org/wiki/\%D0\%94\%D0\%B8\%D1\%81\%D0\%BF\%D0\%B5\%D1\%80\%D1\%81\%D0\%B8\%D0\%BE\%D0\%BD\%D0\%BD\%D1\%8B\%D0\%B9\_\%D0\%B0\%D0\%BD\%D0\%B0\%D0\%BB\%D0\%B8\%D0\%B7}{Russian wikipedia} is more concise and clear on the subject.

‘Types’ of sum of squares and associated confusion:
\begin{itemize}
\item {} 
\sphinxurl{https://mcfromnz.wordpress.com/2011/03/02/anova-type-iiiiii-ss-explained/}

\item {} 
\sphinxurl{https://rcompanion.org/rcompanion/d\_04.html}

\item {} 
\sphinxurl{https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova}

\end{itemize}


\section{References}
\label{\detokenize{topics/anova:references}}
Gelman, A. (2005). Analysis of variance: why it is more important than ever (with discussion). Annals of Statistics 33, 1\textendash{}53. doi:10.1214/009053604000001048


\chapter{Bias-variance tradeoff}
\label{\detokenize{topics/bias_variance_tradeoff:bias-variance-tradeoff}}\label{\detokenize{topics/bias_variance_tradeoff::doc}}
\sphinxhref{https://ars.els-cdn.com/content/image/1-s2.0-S0167739X1500223X-gr11.jpg}{}
\begin{quote}

The bias variance trade-off is maybe not an ideal name, it should maybe have better been called interpolation/extrapolation trade-off. Anyway, the motivation for the name is that that when adding more parameters / complexity, you have
\begin{itemize}
\item {} 
Less systematic error (bias) in your model (supposedly, because it is more flexible, I would argue it depends on what you call error / bias)

\item {} 
More variance in the estimation of the model parameters (because it is more flexible)

\end{itemize}
\end{quote}

Florian Hartig at Cross Validated. \sphinxhref{https://stats.stackexchange.com/users/48591/florian-hartig}{What is the difference between bias and residuals?}


\chapter{Bootstrap}
\label{\detokenize{topics/bootstrap:bootstrap}}\label{\detokenize{topics/bootstrap::doc}}
Bootstrapping is a method to construct empiric distributions of various
statistics (mean, confidence intervals, deviation, etc) by using repreated
sampling from an observed dataset.

A little magic is \sphinxhref{https://stats.stackexchange.com/questions/26088/explaining-to-laypeople-why-bootstrapping-works}{why exactly} taking random samples
like \sphinxcode{\sphinxupquote{{[}1,1,2{]}}}, \sphinxcode{\sphinxupquote{{[}3,2,2{]}}}, \sphinxcode{\sphinxupquote{{[}2,1,3{]}}}, etc is a good idea to approximate
properties of a dataset \sphinxcode{\sphinxupquote{{[}1,2,3{]}}}.

Bootstrap originally proposed by \sphinxhref{http://jeti.uni-freiburg.de/studenten\_seminar/stud\_sem\_SS\_09/EfronBootstrap.pdf}{Bradley Efron in 1979}.
For formal introduction see \sphinxhref{https://www.sciencedirect.com/science/article/pii/S157344120105005X}{Horowitz chapter in Handbook of Econometrics} (2001) and a usage  overview by \sphinxhref{https://core.ac.uk/download/pdf/6494253.pdf}{MacKinnon 2006}.

\sphinxhref{https://www.statisticshowto.datasciencecentral.com/bootstrap-sample/}{}


\section{Toy example}
\label{\detokenize{topics/bootstrap:toy-example}}
\sphinxhref{https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18\_05S14\_Reading24.pdf}{Bootstrap confidence intervals by Jeremy Orloff and Jonathan Bloom, pp. 4-6} provides the following basic code example
for bootstrap. Their full code for this excercise is \sphinxhref{https://math.mit.edu/~dav/05.dir/class24-empiricalbootstrap.r}{here}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Bootstrap}
\PYG{c+c1}{\PYGZsh{} Adapted from https://math.mit.edu/\PYGZti{}dav/05.dir/class24\PYGZhy{}empiricalbootstrap.r}
\PYG{n+nf}{cat}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Example. Empirical boostrap confidence interval for the mean.\PYGZdq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZbs{}n\PYGZsq{}}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n+nf}{c}\PYG{p}{(}\PYG{l+m}{30}\PYG{p}{,}\PYG{l+m}{37}\PYG{p}{,}\PYG{l+m}{36}\PYG{p}{,}\PYG{l+m}{43}\PYG{p}{,}\PYG{l+m}{42}\PYG{p}{,}\PYG{l+m}{43}\PYG{p}{,}\PYG{l+m}{43}\PYG{p}{,}\PYG{l+m}{46}\PYG{p}{,}\PYG{l+m}{41}\PYG{p}{,}\PYG{l+m}{42}\PYG{p}{)}
\PYG{n}{n} \PYG{o}{=} \PYG{n+nf}{length}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{n+nf}{set.seed}\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} for repeatability}

\PYG{c+c1}{\PYGZsh{} sample mean}
\PYG{n}{xbar} \PYG{o}{=} \PYG{n+nf}{mean}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{n+nf}{cat}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{data mean = \PYGZdq{}}\PYG{p}{,}\PYG{n}{xbar}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZbs{}n\PYGZsq{}}\PYG{p}{)}
\PYG{n}{nboot} \PYG{o}{=} \PYG{l+m}{20}
\PYG{c+c1}{\PYGZsh{} Generate 20 bootstrap samples, i.e. an n x 20 array of}
\PYG{c+c1}{\PYGZsh{} random resamples from x.}
\PYG{n}{tmpdata} \PYG{o}{=} \PYG{n+nf}{sample}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{n}\PYG{o}{*}\PYG{n}{nboot}\PYG{p}{,} \PYG{n}{replace}\PYG{o}{=}\PYG{k+kc}{TRUE}\PYG{p}{)}
\PYG{n}{bootstrapsample} \PYG{o}{=} \PYG{n+nf}{matrix}\PYG{p}{(}\PYG{n}{tmpdata}\PYG{p}{,} \PYG{n}{nrow}\PYG{o}{=}\PYG{n}{n}\PYG{p}{,} \PYG{n}{ncol}\PYG{o}{=}\PYG{n}{nboot}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute the means xbar*}
\PYG{n}{xbarstar} \PYG{o}{=} \PYG{n+nf}{colMeans}\PYG{p}{(}\PYG{n}{bootstrapsample}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Compute delta* for each bootstrap sample}
\PYG{n}{deltastar} \PYG{o}{=} \PYG{n}{xbarstar} \PYG{o}{\PYGZhy{}} \PYG{n}{xbar}

\PYG{c+c1}{\PYGZsh{} Find the 0.1 and 0.9 quantiles for deltastar}
\PYG{n}{d} \PYG{o}{=} \PYG{n+nf}{quantile}\PYG{p}{(}\PYG{n}{deltastar}\PYG{p}{,}\PYG{n+nf}{c}\PYG{p}{(}\PYG{l+m}{0.1}\PYG{p}{,}\PYG{l+m}{0.9}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Calculate the 80\PYGZbs{}\PYGZpc{} confidence interval for the mean.}
\PYG{n}{ci} \PYG{o}{=} \PYG{n}{xbar} \PYG{o}{\PYGZhy{}} \PYG{n+nf}{c}\PYG{p}{(}\PYG{n}{d}\PYG{n}{[2}\PYG{n}{]}\PYG{p}{,}\PYG{n}{d}\PYG{n}{[1}\PYG{n}{]}\PYG{p}{)}
\PYG{n+nf}{cat}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Bootstrap confidence interval: [\PYGZsq{}}\PYG{p}{,}\PYG{n}{ci}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{]\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZbs{}n\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Bootstrap do’s and don’ts by Anna Mikusheva}
\label{\detokenize{topics/bootstrap:bootstrap-dos-and-donts-by-anna-mikusheva}}\begin{itemize}
\item {} 
If you have a pivotal statistic,  bootstrap can give a refinement.  So, if you have choice
of statistics, bootstrap a pivotal one.

\item {} 
Bootstrap may fix a finite-sample bias, but cannot help if you have inconsistent estimator.

\item {} 
In  general,  if  something  does  not  work  with  traditional  asymptotics,  the
bootstrap  cannot  fix  your problem. For example, if we have an inconsistent estimate, the
bootstrap bias correction does not fix anything.

\item {} 
Bootstrap could not fix the following problems: weak instruments, parameter on a boundary,
unit root, persistent regressors.

\item {} 
Bootstrap requires re-centering (the null hypothesis to be true).

\end{itemize}

Source: \sphinxhref{https://ocw.mit.edu/courses/economics/14-384-time-series-analysis-fall-2013/lecture-notes/MIT14\_384F13\_lec9.pdf}{MIT lecture notes}


\section{More links (preliminary)}
\label{\detokenize{topics/bootstrap:more-links-preliminary}}\begin{itemize}
\item {} 
\sphinxurl{https://core.ac.uk/download/pdf/6494253.pdf}

\item {} 
\sphinxurl{https://github.com/wmutschl/GMMIndirectInferenceBootstrap}

\item {} 
\sphinxurl{https://www.schmidheiny.name/teaching/bootstrap2up.pdf}

\item {} 
\sphinxurl{http://rosetta.ahmedmoustafa.io/bootstrap/}

\item {} 
\sphinxurl{http://www.cs.cornell.edu/courses/cs1380/2018sp/textbook/chapters/11/2/bootstrap.html}

\item {} 
\sphinxurl{http://economics.fundamentalfinance.com/bootstrap.php}

\end{itemize}


\section{Editor notes}
\label{\detokenize{topics/bootstrap:editor-notes}}\begin{itemize}
\item {} 
\sphinxhref{https://ru.wikipedia.org/wiki/\%D0\%91\%D1\%83\%D1\%82\%D1\%81\%D1\%82\%D1\%80\%D1\%8D\%D0\%BF\_(\%D1\%81\%D1\%82\%D0\%B0\%D1\%82\%D0\%B8\%D1\%81\%D1\%82\%D0\%B8\%D0\%BA\%D0\%B0)}{Russian article} in Wikipedia on bootstrap is much more concise and understandable
than \sphinxhref{https://ru.wikipedia.org/wiki/\%D0\%91\%D1\%83\%D1\%82\%D1\%81\%D1\%82\%D1\%80\%D1\%8D\%D0\%BF\_(\%D1\%81\%D1\%82\%D0\%B0\%D1\%82\%D0\%B8\%D1\%81\%D1\%82\%D0\%B8\%D0\%BA\%D0\%B0)}{English one}.

\end{itemize}


\chapter{Causation, causality}
\label{\detokenize{topics/causation:causation-causality}}\label{\detokenize{topics/causation::doc}}
\begin{sphinxadmonition}{important}{Important:}
Correlation is not causation.
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxhref{https://chrisaulddotcom.wordpress.com/2013/10/08/remarks-on-chen-and-pearl-on-causality-in-econometrics-textbooks/}{causality (not ‘casuality’)}

\end{itemize}


\section{Book of Why by Judea Pearl}
\label{\detokenize{topics/causation:book-of-why-by-judea-pearl}}



\section{History}
\label{\detokenize{topics/causation:history}}\begin{itemize}
\item {} 
\sphinxhref{ucla.in/2mhxKdO}{Pearl, J. (2014). TRYGVE HAAVELMO AND THE EMERGENCE OF CAUSAL CALCULUS. Econometric Theory, 31(1), 152\textendash{}179. https://doi.org/10.1017/s0266466614000231}

\end{itemize}


\chapter{Central limit theorem, CLT}
\label{\detokenize{topics/clt:central-limit-theorem-clt}}\label{\detokenize{topics/clt::doc}}



\chapter{Maximum likelihood}
\label{\detokenize{topics/max-likelihood:maximum-likelihood}}\label{\detokenize{topics/max-likelihood::doc}}
The probability density function \sphinxcode{\sphinxupquote{p = f(x, θ)}} tells you a probability of occurrence
of a random value near \sphinxcode{\sphinxupquote{x}}.  Likelihood is essentially a reverse operation of estimating unknown paramter \sphinxcode{\sphinxupquote{θ}} from the same equation using \sphinxcode{\sphinxupquote{p}} and \sphinxcode{\sphinxupquote{x}}.


\section{Lead by example}
\label{\detokenize{topics/max-likelihood:lead-by-example}}\begin{itemize}
\item {} 
Observations

\item {} 
Probability of observations

\item {} 
Observed sample is considered the most likely one

\item {} 
Maximisation of probability allows to compute distribution parameters

\end{itemize}


\section{Generalisation}
\label{\detokenize{topics/max-likelihood:generalisation}}
We usualy denote a set of parameters like \sphinxcode{\sphinxupquote{μ}} and \sphinxcode{\sphinxupquote{σ}} as \sphinxcode{\sphinxupquote{θ}}, a vector of parameters.
Our task is to estimate parameter \sphinxcode{\sphinxupquote{θ}} given:
\begin{itemize}
\item {} 
a sample of observations of а random variable \sphinxcode{\sphinxupquote{X = (x\(\sb{\text{1}}\), x\(\sb{\text{2}}\), ..., xₙ)}}, and

\item {} 
a pre-defined probability density function \sphinxcode{\sphinxupquote{f(x, θ)}}.

\end{itemize}

\sphinxstylestrong{Solution steps:}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
collect observations \sphinxcode{\sphinxupquote{X = (x\(\sb{\text{1}}\), x\(\sb{\text{2}}\), ..., xₙ)}}

\item {} 
make a decision which probability density function \sphinxcode{\sphinxupquote{f(x, θ)}} is appropriate
for this data

\item {} 
compose joint probability of observations as a function of \sphinxcode{\sphinxupquote{θ}}:
\sphinxcode{\sphinxupquote{L(θ) = f(x\(\sb{\text{1}}\), θ)·f(x\(\sb{\text{2}}\), θ)· ...·f(xₙ, θ)}}.

\item {} 
Come to terms with a principle “if we observed this event, we consider
it was the most probable outcome of all possible events in this distribution”

\item {} 
Find which \sphinxcode{\sphinxupquote{θ}} maiximises joint probability of observations

\end{enumerate}


\section{Code}
\label{\detokenize{topics/max-likelihood:code}}
Python code below below relies on \sphinxcode{\sphinxupquote{scipy.optimixe.minimize}} solver
to find parameters of a normal distribution based on two measurements
of mice weights. It can be easily applied to more observations.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{Maximum likelihood with two mice.}
\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{scipy.optimize} \PYG{k+kn}{import} \PYG{n}{minimize}

\PYG{k}{def} \PYG{n+nf}{dnorm}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{mu}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{sigma}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Normal distribution probability density fucntion.\PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{const} \PYG{o}{=} \PYG{l+m+mi}{1} \PYG{o}{/} \PYG{p}{(}\PYG{n}{sigma} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sqrt}\PYG{p}{(}\PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{power} \PYG{o}{=} \PYG{o}{\PYGZhy{}} \PYG{p}{(}\PYG{n}{x} \PYG{o}{\PYGZhy{}} \PYG{n}{mu}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{/} \PYG{p}{(}\PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{sigma}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}
    \PYG{k}{return}  \PYG{n}{const} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{n}{power}\PYG{p}{)}

\PYG{k}{def} \PYG{n+nf}{log\PYGZus{}likelihood}\PYG{p}{(}\PYG{n}{observed\PYGZus{}x}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Sum of logs of probability densities at *observed\PYGZus{}x*.}
\PYG{l+s+sd}{    Return:}
\PYG{l+s+sd}{       function of mu and sigma}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{def} \PYG{n+nf}{foo}\PYG{p}{(}\PYG{n}{mu}\PYG{p}{,} \PYG{n}{sigma}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{logs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{dnorm}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{mu}\PYG{p}{,} \PYG{n}{sigma}\PYG{p}{)}\PYG{p}{)} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{observed\PYGZus{}x}\PYG{p}{]}
        \PYG{k}{return} \PYG{n+nb}{sum}\PYG{p}{(}\PYG{n}{logs}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{foo}

\PYG{k}{def} \PYG{n+nf}{maximise}\PYG{p}{(}\PYG{n}{f}\PYG{p}{,} \PYG{n}{start\PYGZus{}mu}\PYG{p}{,} \PYG{n}{start\PYGZus{}sigma}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Return mu and lambda, which maximise *f*.\PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{f} \PYG{o}{=} \PYG{k}{lambda} \PYG{n}{p}\PYG{p}{:} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1} \PYG{o}{*} \PYG{n}{l\PYGZus{}func}\PYG{p}{(}\PYG{n}{mu}\PYG{o}{=}\PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{sigma}\PYG{o}{=}\PYG{n}{p}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{res} \PYG{o}{=} \PYG{n}{minimize}\PYG{p}{(}\PYG{n}{f}\PYG{p}{,} \PYG{n}{x0}\PYG{o}{=}\PYG{p}{[}\PYG{n}{start\PYGZus{}mu}\PYG{p}{,} \PYG{n}{start\PYGZus{}sigma}\PYG{p}{]}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{res}\PYG{o}{.}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{res}\PYG{o}{.}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} two mice weigths are given, similar to https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6143748/}
\PYG{n}{events} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{30}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{]}
\PYG{c+c1}{\PYGZsh{} construct likelihood as a function of unknown mu and sigma}
\PYG{n}{l\PYGZus{}func} \PYG{o}{=} \PYG{n}{log\PYGZus{}likelihood}\PYG{p}{(}\PYG{n}{events}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} run maximisation procedure}
\PYG{c+c1}{\PYGZsh{} attention: need a sensible pick for start variables, eg (0, 1) will fail}
\PYG{n}{estimated\PYGZus{}mu}\PYG{p}{,} \PYG{n}{estimated\PYGZus{}sd} \PYG{o}{=} \PYG{n}{maximise}\PYG{p}{(}\PYG{n}{l\PYGZus{}func}\PYG{p}{,} \PYG{n}{start\PYGZus{}mu}\PYG{o}{=}\PYG{l+m+mi}{30}\PYG{p}{,} \PYG{n}{start\PYGZus{}sigma}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} test outcomes}
\PYG{c+c1}{\PYGZsh{}estimated\PYGZus{}mu is 39.99999527669165}
\PYG{k}{assert} \PYG{n}{np}\PYG{o}{.}\PYG{n}{isclose}\PYG{p}{(}\PYG{n}{estimated\PYGZus{}mu}\PYG{p}{,} \PYG{l+m+mi}{40}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}estimated\PYGZus{}sd is 9.999976480910071}
\PYG{k}{assert} \PYG{n}{np}\PYG{o}{.}\PYG{n}{isclose}\PYG{p}{(}\PYG{n}{estimated\PYGZus{}sd}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Result: observed values [30, 50] were most likely coming from}
\PYG{c+c1}{\PYGZsh{}         normal distribution with parameters μ=40 and σ=10.}
\end{sphinxVerbatim}

Other code examples:
\begin{itemize}
\item {} 
\sphinxhref{https://datawookie.netlify.com/blog/2013/08/fitting-a-model-by-maximum-likelihood}{Annotated R code by Andrew Collier (2013)}

\item {} 
\sphinxhref{http://www.johnmyleswhite.com/notebook/2010/04/21/doing-maximum-likelihood-estimation-by-hand-in-r}{Doing Maximum Likelihood Estimation by Hand in R by John Myles White (2010)}

\item {} 
\sphinxhref{https://www.codementor.io/zhuojiadai/julia-vs-r-vs-python-simple-optimization-gnqi4njro}{Julia vs R vs Python Simple Optimization by Zhuo Jiadai (2018)}

\end{itemize}


\section{Links}
\label{\detokenize{topics/max-likelihood:links}}\begin{itemize}
\item {} 
Nice video with \sphinxhref{https://www.youtube.com/watch?v=XepXtl9YKwc}{weight of mice}

\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/112451/maximum-likelihood-estimation-mle-in-layman-terms}{Maximum likelihood estimation in layman terms}

\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/180420/why-is-maximum-likelihood-estimation-considered-to-be-a-frequentist-technique/190695\#190695}{Why is maximum likelihood estimation considered to be a frequentist technique}

\item {} 
\sphinxhref{https://nsu.ru/mmf/tvims/chernova/ms/lec/node14.html}{Very accessible math treatment (in Russian)}

\item {} 
\sphinxhref{https://www.youtube.com/watch?v=2iRIqkm1mug}{Tourist sees a fountain (also in Russian)}

\end{itemize}


\chapter{Mode}
\label{\detokenize{topics/mode:mode}}\label{\detokenize{topics/mode::doc}}



\chapter{Ordinary least squares, OLS}
\label{\detokenize{topics/ols:ordinary-least-squares-ols}}\label{\detokenize{topics/ols::doc}}
OLS is at the core of econometrics curriculum, it is easily derived and
highly practical to familiarise a learner with regression possibilites
and limitations.

The usual way to teach OLS is to present assumptions and show how to deal
with their violations as indicated below in a review chart from Kennedy’s
textbook.

\noindent\sphinxincludegraphics{{peter_kennedy_on_ols}.png}

Math:

\(Y = \beta X + \epsilon\), \(\epsilon\) is iid, normal with finite variance.

Common steps:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
specify model: select explanatory variables, transform them if needed

\item {} 
estimate coefficients

\item {} 
elaborate on model quality (the hardest part)

\item {} 
go to 1 if needed

\item {} 
know what model \sphinxstyleemphasis{does not} show (next hardeer part)

\end{enumerate}

What may go wrong:
\begin{itemize}
\item {} 
residuals are not random

\item {} 
variables are cointegrated

\item {} 
multicollinearity in regressors

\item {} 
residuals depend on x (heteroscedasticity)

\item {} 
inference is not causality

\item {} 
wrong signs, insignificant coefficients

\item {} 
variable normalisation was not described

\end{itemize}

Discussion:
\begin{itemize}
\item {} 
why sum of squares as a loss function?

\item {} 
connections to bayesian estimation

\item {} 
is R2 useful or dangerous?

\end{itemize}

Implementations:
\begin{itemize}
\item {} 
\sphinxhref{https://github.com/wch/r-source/blob/0f07757ad10ca31251b28a2c332812e63c0acf38/src/library/stats/R/lm.R}{lm function in
R}

\item {} 
\sphinxhref{https://github.com/statsmodels/statsmodels/blob/master/statsmodels/regression/linear\_model.py}{OLS class in python
statsmodels}

\item {} 
\sphinxhref{https://github.com/scipy/scipy/blob/v1.1.0/scipy/linalg/basic.py\#L1048-L1265}{python scypi least
squares}

\item {} 
julia \sphinxhref{https://github.com/giob1994/Alistair.jl}{Alistair}, GLM.jl,
Regression.jl

\item {} 
\sphinxhref{https://www.kaggle.com/nicapotato/in-depth-simple-linear-regression}{Replication
examples}

\item {} 
check unsorted \sphinxhref{ols\_links.txt}{links about OLS} - but it is not
better than googling on your own

\end{itemize}


\chapter{Principal components analysis, PCA}
\label{\detokenize{topics/pca:principal-components-analysis-pca}}\label{\detokenize{topics/pca::doc}}
Math:

Assumptions:

Usual steps:

What may go wrong:

Discussion:

Replication examples:

Links:
\begin{itemize}
\item {} 
\sphinxurl{https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/2700\#2700}

\item {} 
\sphinxurl{https://scikit-learn.org/stable/auto\_examples/decomposition/plot\_pca\_3d.html\#sphx-glr-auto-examples-decomposition-plot-pca-3d-py}

\item {} 
\sphinxurl{https://stats.stackexchange.com/questions/48214/replicating-shalizis-new-york-times-pca-example?rq=1}

\end{itemize}

Projection, rejection, PCA:
\begin{itemize}
\item {} 
\sphinxurl{https://stackoverflow.com/questions/52288029/function-that-computes-projection-and-recostruction-error-using-numpy-python/52290082\#52290082}

\item {} 
\sphinxurl{http://www.cs.cmu.edu/~guestrin/Class/15781/slides/pca-mdps-annotated.pdf}

\item {} 
\sphinxurl{https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/least-squares-determinants-and-eigenvalues/projections-onto-subspaces/MIT18\_06SCF11\_Ses2.2sum.pdf}

\end{itemize}


\chapter{Simulation}
\label{\detokenize{topics/simulation:simulation}}\label{\detokenize{topics/simulation::doc}}\begin{quote}

A very useful tool is simulation \textendash{} with that we can examine the properties of our tools in situations very like those it appears our data may have arisen from, and so either use them in the comforting knowledge that they have good properties in those cases (or, sometimes, see that  they don’t work as well as we might hope).
\end{quote}

From an \sphinxhref{https://stats.stackexchange.com/a/130798/211794}{answer to Why do we care so much about normally distributed error terms} by \sphinxhref{https://stats.stackexchange.com/users/805/glen-b}{Glen\_b}.

\begin{sphinxadmonition}{note}{To cover next: Concepts}
\begin{itemize}
\item {} 
indentification

\item {} 
inference

\item {} 
overfitting

\item {} 
\sphinxhref{https://mpra.ub.uni-muenchen.de/59008/}{spurious regression}

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{To cover next: Theorems}
\begin{itemize}
\item {} 
\sphinxhref{http://onlinestatbook.com/2/probability/bayes\_demo.html}{Bayes theorem}

\item {} 
Gauss-Markov theorem

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{To cover next: Research design}
\begin{itemize}
\item {} 
replication, replicability

\item {} 
\sphinxhref{https://fs.blog/2018/01/complexity-bias/}{complexity bias}

\item {} 
\sphinxhref{https://voxeu.org/article/publishing-and-promotion-economics-tyranny-top-five/}{publishing and promotion}

\end{itemize}
\end{sphinxadmonition}


\chapter{2. Textbooks and courses}
\label{\detokenize{textbook/index:textbooks-and-courses}}\label{\detokenize{textbook/index::doc}}

\section{Mathematic preliminaries}
\label{\detokenize{textbook/preliminaries:mathematic-preliminaries}}\label{\detokenize{textbook/preliminaries::doc}}
Typical prerequisites for statistics and econometrics are:
\begin{itemize}
\item {} 
linear algebra

\item {} 
calculus

\item {} 
probability

\end{itemize}

They usually take 2-4 semester in college. Linear algebra is fully covered by
\sphinxhref{http://vmls-book.stanford.edu}{VMLS}, and probability is exposed in \sphinxhref{http://pages.cs.wisc.edu/~tdw/files/cookbook-en.pd}{PSC}, even though it is a compact reference, not formally a textbook. \sphinxhref{http://www.scipy-lectures.org}{Scipy lectures} are a great one-stop resource for numerical computing basics.

I do not have a one single source to recommend for calculus yet.


\subsection{Linear Algebra}
\label{\detokenize{textbook/preliminaries:linear-algebra}}\begin{itemize}
\item {} 
\sphinxhref{http://vmls-book.stanford.edu}{Vectors, Matrices, and Least Squares (VLMS)}

\item {} 
You can also check Computational Linear Algebra repository from \sphinxstyleemphasis{fast.ai} \sphinxhref{https://github.com/fastai/numerical-linear-algebra}{here}.

\end{itemize}


\subsection{Calculus}
\label{\detokenize{textbook/preliminaries:calculus}}
\sphinxhref{https://arxiv.org/abs/1802.01528}{The Matrix Calculus You Need For Deep Learning}
recommends \sphinxhref{https://www.khanacademy.org/math/differential-calculus}{Khan Academy differential calculus course}, but it is not a single downloadable reference. \sphinxstyleemphasis{fast.ai}
also has a \sphinxhref{http://wiki.fast.ai/index.php/Calculus\_for\_Deep\_Learning}{calculus intro},
going from start to derivatives in deep learning quickly.


\subsection{Probability and statistics}
\label{\detokenize{textbook/preliminaries:probability-and-statistics}}\begin{itemize}
\item {} 
\sphinxhref{http://pages.cs.wisc.edu/~tdw/files/cookbook-en.pd}{Probability and Statistics Cookbook (PSC)}

\end{itemize}


\subsection{Numerical computing}
\label{\detokenize{textbook/preliminaries:numerical-computing}}\begin{itemize}
\item {} 
\sphinxhref{http://www.scipy-lectures.org}{Scipy lectures: one document to learn numerics, science, and data with Python}

\end{itemize}


\section{Statistical inference}
\label{\detokenize{textbook/statistics:statistical-inference}}\label{\detokenize{textbook/statistics::doc}}
This page is a draft.

Some discussions about a good book:
\begin{itemize}
\item {} 
\sphinxhref{https://mathoverflow.net/questions/31655/statistics-for-mathematicians}{Math Overflow: Statistics for Mathematicians}

\item {} 
\sphinxhref{https://stats.stackexchange.com/questions/91863/what-to-learn-after-casella-berger}{Stack Exchange: What to learn after Casella/Berger}

\end{itemize}


\subsection{Topics}
\label{\detokenize{textbook/statistics:topics}}
Review of probability:
\begin{itemize}
\item {} 
random variables, outcomes, probability

\item {} 
distributions, pdf/cdf

\end{itemize}

Mathematic statistics itself:
\begin{itemize}
\item {} 
idea: learn about data generating process (DGP) from a sample

\item {} 
sample/realisation as a random vector

\item {} 
statistic as a function of sample

\item {} 
parameter inference:
\begin{itemize}
\item {} 
point estimation and methods (estimators)

\item {} 
estimator quality (bias, consistency, efficiency)

\end{itemize}

\item {} 
confidence intervals (CI)

\item {} 
hypothesis testing (HT), types of errors

\item {} 
analysis of variance and regression

\end{itemize}

See an example of \sphinxhref{http://comet.lehman.cuny.edu/owen/teaching/mat327/syllabus\_mat327\_782\_2018fa.pdf}{stated learning objectives}




\subsection{Key textbook}
\label{\detokenize{textbook/statistics:key-textbook}}
Casella, Berger. Statistical Inference.
\begin{itemize}
\item {} 
\sphinxhref{https://fsalamri.files.wordpress.com/2015/02/casella\_berger\_statistical\_inference1.pdf}{link}

\end{itemize}


\subsection{Other choices}
\label{\detokenize{textbook/statistics:other-choices}}
Larry Wasserman. All of Statistics: A Concise Course in Statistical Inference

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{} [text 1](https://www.ic.unicamp.br/\PYGZti{}wainer/cursos/1s2013/ml/livro.pdf)
\PYGZhy{} [text 2](http://static.stevereads.com/papers\PYGZus{}to\PYGZus{}read/all\PYGZus{}of\PYGZus{}statistics.pdf)
\PYGZhy{} [Amazon](https://www.amazon.com/All\PYGZhy{}Statistics\PYGZhy{}Statistical\PYGZhy{}Inference\PYGZhy{}Springer/dp/0387402721)
\end{sphinxVerbatim}

Efron, Hastie. Computer Age Statistical Inference: Algorithms, Evidence and Data Science.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{} https://web.stanford.edu/\PYGZti{}hastie/CASI\PYGZus{}files/PDF/casi.pdf
\end{sphinxVerbatim}


\subsection{Supplements}
\label{\detokenize{textbook/statistics:supplements}}
\sphinxhref{https://mason.gmu.edu/~jgentle/books/MathStat.pdf}{James Gentle. A theory of statistics.}

\sphinxhref{http://professor.ufabc.edu.br/~nelson.faustino/Ensino/IPE2016/Livros/Morris\%20H\%20DeGroot\_\%20Mark\%20J\%20Schervish-Probability\%20and\%20statistics-Pearson\%20Education\%20\%20(2012}{De Groot and Shervish}\%20(1).pdf)

\sphinxhref{https://bit.ly/2zWyyff}{Herman J. Bierens. Introduction to the Mathematical and Statistical Foundations of Econometrics}

Aris Spanos. Probability Theory and Statistical Inference: Econometric Modeling
with Observational Data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{} [link](https://wilfridomtz.files.wordpress.com/2014/08/cambridge\PYGZhy{}university\PYGZhy{}press\PYGZhy{}probability\PYGZhy{}theory\PYGZhy{}and\PYGZhy{}statistical\PYGZhy{}inference\PYGZhy{}842pg.pdf)
\end{sphinxVerbatim}

\sphinxhref{https://fac.ksu.edu.sa/sites/default/files/probability\_and\_statistics\_for\_engineers\_and\_scientisst.pdf}{Probability and Statistics for Engineers and Scientists (PSES)}




\subsection{Other reading}
\label{\detokenize{textbook/statistics:other-reading}}
Statistical Inference as Severe Testing: How to Get Beyond the Statistics Wars

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{} [Amazon](https://www.amazon.com/Statistical\PYGZhy{}Inference\PYGZhy{}Severe\PYGZhy{}Testing\PYGZhy{}Statistics/dp/1107664640)
\PYGZhy{} very philosophic reading
\end{sphinxVerbatim}

Peter M. Aronow, Benjamin T. Miller. Foundations of Agnostic Statistics.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{} [Google Book (fragments)](https://books.google.ru/books?id=u1N\PYGZhy{}DwAAQBAJ\PYGZam{}printsec=frontcover\PYGZam{}hl=ru\PYGZam{}source=gbs\PYGZus{}ge\PYGZus{}summary\PYGZus{}r\PYGZam{}cad=0\PYGZsh{}v=onepage\PYGZam{}q\PYGZam{}f=false)
\PYGZhy{} [book proposal](http://aronow.research.yale.edu/aronowmillerproposal.pdf)
\PYGZhy{} simplictic
\end{sphinxVerbatim}


\subsection{Papers}
\label{\detokenize{textbook/statistics:papers}}
\sphinxhref{http://static.stevereads.com/papers\_to\_read/statistical\_inference\_the\_big\_picture.pdf}{Statistical Inference:  The Big Picture. Robert E. Kass (2006)}

\sphinxhref{https://www.researchgate.net/publication/271856948\_A\_short\_history\_of\_probability\_theory\_and\_its\_applications}{A short history of probability theory and its applications.
International Journal of Mathematical Education. January 2015. Kanadpriya Basu.}


\subsection{In Russian}
\label{\detokenize{textbook/statistics:in-russian}}
\sphinxhref{http://cyber.sibsutis.ru:82/Monarev/docs/nauka/MV\_Probability/MVsa\_Statistics\%20and\%20applications/0417.Kramer-Matem\_Metodi\_Statistiki.pdf}{Cramer, 1946, Russian translation}, timeless! also has dataset if wheat yeilds.

Also concise version of lectures \sphinxhref{http://math.csu.ru/new\_files/students/lectures/teor\_ver/solovev\_teor\_ver.pdf}{here (in Russian)}


\section{Econometrics}
\label{\detokenize{textbook/econometrics:econometrics}}\label{\detokenize{textbook/econometrics::doc}}

\subsection{General textbooks}
\label{\detokenize{textbook/econometrics:general-textbooks}}\begin{itemize}
\item {} 
Thread about \sphinxhref{http://www.urch.com/forums/phd-economics/127240-just-finished-intro-wooldridge-gurajati-whats-best-text-next-self-study.html}{picking a textbook}

\item {} 
Favorite introductory book: \sphinxhref{https://scholar.google.com/scholar?cluster=16057448950849214316\&hl=en\&as\_sdt=0,5\&sciodt=0,5}{Peter Kennedy. A Guide To Econometrics}

\item {} 
Very condensed synopsis of \sphinxhref{https://github.com/tyleransom/EconometricsLabs/blob/master/econometricsCheatSheet.pdf}{undergrad econometrics}

\end{itemize}

Some well-known texts:
\begin{itemize}
\item {} 
Greene

\item {} 
Dougherty

\item {} 
Hayashi

\item {} 
Stock and Watson

\item {} 
Verbeek

\item {} 
\sphinxhref{https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics.pdf}{Hansen. Econometircs}

\item {} 
\sphinxhref{http://assets.press.princeton.edu/chapters/c10141.pdf}{Sargent-Hansen}

\end{itemize}


\subsection{Cross Section and Panel Data}
\label{\detokenize{textbook/econometrics:cross-section-and-panel-data}}\begin{itemize}
\item {} 
\sphinxhref{http://bit.ly/2PsGoE6}{Wooldridge. Econometric Analysis of Cross Section and Panel Data}

\item {} 
\sphinxhref{https://press.princeton.edu/titles/8769.html}{МНЕ}, with criticisms by:
\begin{itemize}
\item {} 
Diebold: \sphinxhref{https://fxdiebold.blogspot.com/2015/01/mostly-harmless-econometrics.html}{“sub-sub-sub-area of applied econometrics”}

\item {} 
\sphinxhref{https://p-hunermund.com/2017/02/22/judea-pearl-on-angrist-and-pischke}{J. Pearl}

\end{itemize}

\end{itemize}

Note that MHE is one of few books with excercises \sphinxhref{https://github.com/vikjam/mostly-harmless-replication}{reproduced on github}.

Criticism of MHE:
\begin{quote}

Rather, it’s a companion for a highly-specialized group of applied non-structural micro-econometricians hoping to estimate causal effects using non-experimental data and largely-static, linear, regression-based methods. It’s a novel treatment of that sub-sub-sub-area of applied econometrics, but pretending to be anything more is most definitely harmful, particularly to students, who have no way to recognize the charade as a charade.
\end{quote}

\sphinxurl{https://fxdiebold.blogspot.com/2015/01/mostly-harmless-econometrics.html}
\begin{itemize}
\item {} 
\sphinxhref{https://www.schmidheiny.name/teaching/shortguides.htm}{Lecture Notes in Microeconometrics} - nicely presented topics in econometrics for microeconomics from OLS to Bootstrap. Guides to software.

\end{itemize}


\subsection{Time Series}
\label{\detokenize{textbook/econometrics:time-series}}\begin{itemize}
\item {} 
\sphinxhref{https://scholar.google.com/scholar?cluster=7489561659476003036\&hl=en\&as\_sdt=0,5}{Hamilton}

\item {} 
\sphinxhref{https://www.sas.upenn.edu/~fdiebold/Teaching706/TimeSeriesEconometrics.pdf}{Diebold}

\item {} 
\sphinxhref{https://www.sciencedirect.com/science/article/pii/S1573441284020092}{Granger/Watson time series chapter in Handbook of Econometrics}

\item {} 
\sphinxhref{http://time-series.net/yahoo\_site\_admin/assets/docs/enders4\_pptsch04.684612.pdf}{Enders}

\item {} 
\sphinxhref{https://www.reed.edu/economics/parker/312/readings.html\#S8}{Jeffrey Parker. Fundamental Concepts of Time-Series Econometrics} in \sphinxstyleemphasis{Theory and Practice of Econometrics. Reed College course}

\end{itemize}

Macroeconomic time series:
\begin{itemize}
\item {} 
\sphinxhref{https://faculty.chicagobooth.edu/john.cochrane/research/Papers/time\_series\_book.pdf}{John H. Cochrane. Time Series for Macroeconomics and Finance.}

\item {} 
\sphinxhref{https://www3.nd.edu/~esims1/time\_series\_notes\_sp13.pdf}{Eric Sims. Graduate Macro Theory II: Notes on Time Series}

\item {} 
\sphinxhref{http://larspeterhansen.org/wp-content/uploads/2017/11/jpecurrent.pdf}{Lars Peter Hansen. Time Series Econometrics in Macroeconomics and Finance}

\item {} 
\sphinxhref{http://home.bi.no/a1010297/timeseries/}{Hilde C. Bjørnland and Leif Anders Thorsrud. Applied time series for macroeconomics.} (not open source, but good table of contents and
has MATLAB code)

\item {} 
\sphinxhref{http://www.karlwhelan.com/MAMacro/part1.pdf}{Karl Whelan. Time Series and Macroeconomics.} (also see RATS code and other lectures on the web site)

\end{itemize}




\subsection{Вayesian Methods}
\label{\detokenize{textbook/econometrics:ayesian-methods}}\begin{itemize}
\item {} 
\sphinxhref{http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/}{Bayesian Methods for Hackers} has programming-first approach.

\item {} 
\sphinxhref{https://twitter.com/canyon289/status/1148709146478465025}{SciPy 2019 Lecture on Bayesian Model Evaluation and Criticism}.

\item {} 
\sphinxhref{https://stackoverflow.com/questions/10059594/a-simple-explanation-of-naive-bayes-classification}{A simple explanation of Naive Bayes Classification}, an overwhelmingly popular
StackOverflow answer.

\end{itemize}


\section{… and its history}
\label{\detokenize{textbook/history:and-its-history}}\label{\detokenize{textbook/history::doc}}

\subsection{Landmark events}
\label{\detokenize{textbook/history:landmark-events}}\begin{itemize}
\item {} 
\sphinxhref{http://jse.amstat.org/v9n3/stanton.html}{Galton} and Pearson

\item {} 
Tinbergen, Haavelmo

\item {} 
Cowles Commission

\item {} 
Lucas and Sims critique

\end{itemize}


\subsection{Overviews}
\label{\detokenize{textbook/history:overviews}}\begin{itemize}
\item {} 
\sphinxhref{http://ftp.iza.org/dp2458.pdf}{Econometrics: A Bird’s Eye View}

\item {} 
\sphinxhref{https://www.le.ac.uk/economics/research/RePEc/lec/leecon/dp14-05.pdf}{Econometrics: An Historical Guide for the Uninitiated}

\item {} 
\sphinxhref{https://www.researchgate.net/publication/24119912\_The\_First\_Fifty\_Years\_of\_Modern\_Econometrics}{The First Fifty Years of Modern Econometrics}

\end{itemize}


\subsection{By topic}
\label{\detokenize{textbook/history:by-topic}}\begin{itemize}
\item {} 
\sphinxhref{ucla.in/2mhxKdO}{Pearl, J. (2014). Tygve Haavelmo and the emergence of causal calculus. Econometric Theory, 31(1), 152\textendash{}179.}

\item {} 
\sphinxhref{https://arxiv.org/pdf/0808.2902.pdf}{A Short History of Markov Chain Monte Carlo (arxiv)}

\item {} 
\sphinxhref{https://beatricecherrier.wordpress.com/2018/10/15/working-on-1960s-macroeconometrics-theres-an-echo-on-the-line}{Working on 1960s macroeconometrics (blog)}

\item {} 
\sphinxhref{https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=2837766}{Criticizing the Lucas Critique: Macroeconometricians’ Response to Robert Lucas}

\item {} 
\sphinxhref{https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf}{W N Venables. Exegeses on Linear Models (1998)}

\end{itemize}


\section{… body of knowledge}
\label{\detokenize{textbook/ways-into-econometrics:body-of-knowledge}}\label{\detokenize{textbook/ways-into-econometrics::doc}}
What exactly is a body of knowledge of econometrics? Surely it is a set of
teaching curricula at universities and accompaigning textbooks and reading lists,
but what if you needed construct a review of the field rather quickly?
The following approaches might be useful.


\subsection{1. Textbook structure}
\label{\detokenize{textbook/ways-into-econometrics:textbook-structure}}
The undergraduate textbook structure often repeats itself: OLS, estimator
properties, some of OLS deviations/extensions, logit/probit + maximum likelihood,
time series and maybe a bit of panels and simultaneous equations.

More textbook analysis may be found in 2017 Angrist and Pischke article \sphinxhref{https://pubs.aeaweb.org/doi/pdf/10.1257/jep.31.2.125}{Undergraduate Econometrics Instruction: Through Our Classes, Darkly}, below is a summary table (some of it does not escape \sphinxhref{https://fxdiebold.blogspot.com/2017/02/econometrics-angrist-and-pischke-are-at.html}{criticism}).

\sphinxhref{../../\_static/darkly.jpg}{\sphinxincludegraphics{{darkly}.jpg}}


\subsection{2. Econometric software manuals}
\label{\detokenize{textbook/ways-into-econometrics:econometric-software-manuals}}
Gretl and EViews have quite comprehensive manuals covering
principal applications of the software. They both qualify as
textbooks in econometrics:
\begin{itemize}
\item {} 
\sphinxhref{http://gretl.sourceforge.net/gretl-help/gretl-guide.pdf}{gretl}

\item {} 
\sphinxhref{https://www.le.ac.uk/users/dsgp1/COURSES/THIRDMET/MANUALS/ebook.pdf}{course based on gretl}

\item {} 
\sphinxhref{http://www.eviews.com/EViews8/EViews8/EViews\%208\%20Users\%20Guide\%20I.pdf}{Eviews I}

\item {} 
\sphinxhref{http://www.eviews.com/EViews8/EViews8/EViews\%208\%20Users\%20Guide\%20II.pdf}{Eviews II}

\end{itemize}

Additionally one can look into {[}R package system for econometrics{]}  (\sphinxurl{https://cran.r-project.org/web/views/Econometrics.html}), MATLAB \sphinxhref{https://www.mathworks.com/help/econ/}{manual} and \sphinxhref{http://fmwww.bc.edu/ec-p/software/matlab/mbook.pdf.old}{course}.

Manulas of some less popular packages:
\begin{itemize}
\item {} 
\sphinxhref{https://www.estima.com/enders/RATS\_Programming\_Manual.pdf}{RATS}

\item {} 
\sphinxhref{https://www.doornik.com/pcgive/index.html}{PcGive}

\item {} 
\sphinxhref{http://store.econometrics.com/shazam/shazam\_reference\_manual\_11\_interior.pdf}{Shazam}

\item {} 
\sphinxhref{https://www.danielmsullivan.com/econtools/metrics.html}{econtools (STATA flavour)}

\end{itemize}


\subsection{3. Handbook of Econometrics}
\label{\detokenize{textbook/ways-into-econometrics:handbook-of-econometrics}}
Elsevier \sphinxhref{https://www.sciencedirect.com/handbook/handbook-of-econometrics/vol/1/suppl/C}{Handbook of Econometrics}
is a  publication series running since 1983. It now features 77 chapters in 6 volumes. Many earlier articles are foundational, but quite a few recent ones are about some really narrow
subjects areas. I think the volume TOC is great, but publications are overpriced
(it’s Elsevier).


\section{… mindmap}
\label{\detokenize{textbook/mindmap:mindmap}}\label{\detokenize{textbook/mindmap::doc}}
It would be great to show a modern roadmap in econometrics starting
from mathematic foundations (linear algebra, calculus, probability) to
econometrics to computationally intensive data processing tasks.
I’ve seen this being approached as \sphinxhref{https://www.quora.com/How-do-I-design-a-curriculum-to-teach-myself-statistics}{clusters of courses},
Khan Academy has goals by subject, but I think there is more that
can be done.


\subsection{An (over)simplified view of econometrics curriculum}
\label{\detokenize{textbook/mindmap:an-over-simplified-view-of-econometrics-curriculum}}\begin{itemize}
\item {} 
linear algebra, calculus, probability and statistical inference

\item {} 
OLS (assumptions, violations, fixes + estimatore quality)

\item {} 
limited depenedent variables + maximum likelihood

\item {} 
intrumental variables

\item {} 
time series, state space representation

\item {} 
panel data

\item {} 
classifications

\item {} 
systems of equations

\end{itemize}


\subsection{Key areas}
\label{\detokenize{textbook/mindmap:key-areas}}\begin{itemize}
\item {} 
data structures (crosssection, time series, panel)

\item {} 
inference methods
\begin{itemize}
\item {} 
model specification

\item {} 
estimation procedure

\item {} 
model evaluation

\end{itemize}

\item {} 
use cases

\end{itemize}


\subsection{Additional topics}
\label{\detokenize{textbook/mindmap:additional-topics}}\begin{itemize}
\item {} 
simulation (Monte Carlo, bootstrap)

\item {} 
transformations (PCA)

\end{itemize}

OLS Extensions:
\begin{itemize}
\item {} 
GMM

\item {} 
2,3 stage OLS

\item {} 
quantile regressions

\item {} 
lasso, rigde

\end{itemize}

Estimation:
\begin{itemize}
\item {} 
maximum likelihood

\item {} 
bayesian estimation

\item {} 
mcmc (see reddit post)

\end{itemize}

Time series:
\begin{itemize}
\item {} 
time series, stationarity, unit root

\item {} 
state space representation, Kalman filter

\item {} 
fractional integration

\item {} 
seasonal adjustment

\item {} 
(vector) error correction model, VECM

\item {} 
structural breaks

\end{itemize}


\subsection{User profiles}
\label{\detokenize{textbook/mindmap:user-profiles}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
“Numerate biologists” - solve a domain problem in biology, psychology, social sciences

\item {} 
“Want to hit a ‘Run’ button” - quick results without thinking, typical of students

\item {} 
“I’m doing XYZ now!” - excited adopters, writing a piece on Medium full of acronyms

\item {} 
“Sane econometrics” - appropriate methods with clear, accessible explaination, rare trait

\item {} 
“Asymptotics” - publish evermore sophisticated articles to secure academic career

\end{enumerate}


\subsection{Discussion}
\label{\detokenize{textbook/mindmap:discussion}}
\sphinxhref{https://www.nber.org/papers/w23144}{Undergraduate Econometrics Instruction: Through Our Classes, Darkly. NBER/IZA} and a criticism of \sphinxhref{https://fxdiebold.blogspot.com/2017/02/econometrics-angrist-and-pischke-are-at.html}{G1/G2 goals}


\section{Machine learning (ML) and deep learning (DL)}
\label{\detokenize{textbook/ml-dl:machine-learning-ml-and-deep-learning-dl}}\label{\detokenize{textbook/ml-dl::doc}}

\subsection{Books}
\label{\detokenize{textbook/ml-dl:books}}

\subsubsection{ML}
\label{\detokenize{textbook/ml-dl:ml}}\begin{itemize}
\item {} 
\sphinxhref{https://www-bcf.usc.edu/~gareth/ISL/ISLR\%20First\%20Printing.pdf}{An Introduction to Statistical Learning. Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani}

\end{itemize}


\subsubsection{DL}
\label{\detokenize{textbook/ml-dl:dl}}\begin{itemize}
\item {} 
\sphinxhref{https://www.deeplearningbook.org/}{Deep Learning. Ian Goodfellow and Yoshua Bengio and Aaron Courville}

\end{itemize}


\subsubsection{Slightly overcomplicated extras}
\label{\detokenize{textbook/ml-dl:slightly-overcomplicated-extras}}\begin{itemize}
\item {} 
\sphinxhref{https://www.microsoft.com/en-us/research/publication/foundations-of-data-science/}{Foundations of Data Science}

\item {} 
\sphinxhref{https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html}{Understanding Machine Learning: From Theory to Algorithms}

\end{itemize}


\subsection{Courses}
\label{\detokenize{textbook/ml-dl:courses}}

\subsubsection{ML}
\label{\detokenize{textbook/ml-dl:id1}}\begin{itemize}
\item {} 
\sphinxhref{https://github.com/Yorko/mlcourse.ai}{ods}

\item {} 
\sphinxhref{https://www.coursera.org/learn/machine-learning}{Andrew Ng course}

\item {} 
\sphinxhref{https://datascience.quantecon.org/applications/}{QuantEcon ML application}

\end{itemize}


\subsubsection{DL}
\label{\detokenize{textbook/ml-dl:id2}}\begin{itemize}
\item {} 
\sphinxhref{https://www.fast.ai/}{fast.ai}

\item {} 
\sphinxhref{https://www.deeplearning.ai/deep-learning-specialization}{deeplearning.ai}

\end{itemize}


\chapter{3. The science of teaching}
\label{\detokenize{how-to-teach:the-science-of-teaching}}\label{\detokenize{how-to-teach::doc}}
Notes on technical pedagogy.


\section{Ideas}
\label{\detokenize{how-to-teach:ideas}}\begin{itemize}
\item {} 
“Overarching education” (plenty of math and fundimentals, aimed at systemic thinking,
practical applications derived later) is expensive method of teaching.

\item {} 
Student motivation is scarce, information is abundant. Teaching is a guidance (esp masters level).

\item {} 
Can teach programming first, and followup with more solid math second, if ever (programming allows experimenting).

\item {} 
Need open source textbooks, able to update and share parts of text as well as
interactive excercises. Static site generators are not fully there yet.

\end{itemize}


\section{Links}
\label{\detokenize{how-to-teach:links}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxhref{http://third-bit.com/10rules/\#teaching}{10 rules of teaching} by Greg Wilson (@gvwilson) starts with rule \#1 “Be kind: all else is details.” More detail is at \sphinxhref{http://teachtogether.tech/en/}{teachtogether.tech}.

\item {} 
Nick Huntington-Klein \sphinxhref{https://twitter.com/nickchk/status/1114956341913645058}{proposes a course structure} based on statistical programming, and causal inference/research design, with regressions postponed.

\end{enumerate}

 
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
Allen Downey has a \sphinxhref{https://twitter.com/AllenDowney/status/1118255413575680000}{presentation about teaching physical modelling} and sequencing of math and programming.

\end{enumerate}

 

4. Very introductory courses are good for building student confidence and making simple things simple. They prevent gate-keeping (maybe a reason why they are attacked). See a thread by
\sphinxhref{https://twitter.com/RochelleTerman/status/1126642900006252544}{Rochelle Terman on teaching computational social science}.


\chapter{Data}
\label{\detokenize{data:data}}\label{\detokenize{data::doc}}

\section{Large collections}
\label{\detokenize{data:large-collections}}\begin{itemize}
\item {} 
Python libraries \sphinxhref{https://kolesnikov.ga/Datasets\_in\_Python/}{statsmodels, sci-learn and seaborn}
and \sphinxhref{https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html}{R itself} have build-in datasets.

\item {} 
gretl has extensive selection of datasets, including \sphinxhref{http://gretl.sourceforge.net/gretl\_data.html}{data from key textbooks}.

\item {} 
Well known dataset repository is \sphinxhref{http://archive.ics.uci.edu/ml/datasets.html}{UCI}.

\item {} 
\sphinxhref{https://www.kaggle.com/datasets}{Kaggle} obviously has plenty of datasets.

\item {} 
Sheffield University made a good  listing of \sphinxhref{https://www.sheffield.ac.uk/mash/data}{datasets for teaching}.

\item {} 
Australian National Centre for Econometric Research website has
a useful \sphinxhref{http://www.ncer.edu.au/resources/data-and-code.php}{Data and code}
section.

\item {} 
\sphinxhref{https://toolbox.google.com/datasetsearch}{Google Dataset search} is not yet as good as
main Google search, but will surely improve.

\item {} 
\sphinxhref{https://fred.stlouisfed.org/}{FRED}, \sphinxhref{https://www.quandl.com/}{Quandl} and \sphinxhref{https://db.nomics.world/}{dbnomics} are standard sources for macroeconomic data. My own effort for clean Russian macro time series - \sphinxhref{https://github.com/mini-kep}{mini-kep}.

\end{itemize}


\section{Individual datasets}
\label{\detokenize{data:individual-datasets}}\begin{itemize}
\item {} 
\sphinxhref{https://github.com/rfordatascience/tidytuesday\#datasets}{Tidy Tuesday} publishes weekly
datasets and accompanying articles.

\item {} 
Nick Huntington-Klein provides a variety of extra examples of \sphinxhref{http://nickchk.com/econometrics.html\#Rdata}{data importable into R}.

\item {} 
I extracted a small, but illustartive dataset about \sphinxhref{https://twitter.com/PogrebnyakE/status/1108438155554930688}{lightbulb survival rate}.

\item {} 
\sphinxhref{https://www.google.com/search?client=firefox-b-d\&q=sunspot+data}{Sunspot data} is listed at variety of sources.

\end{itemize}


\chapter{Software}
\label{\detokenize{software:software}}\label{\detokenize{software::doc}}
Below is a small chart that outlines common options for statistics / econometrics software.
gretl, EViews and MATLAB tend to have better-organised documentation. My personal choices:
\begin{itemize}
\item {} 
if I had to choose just one: python;

\item {} 
if I had to choose other two: R (libraries) and gretl (documentation);

\item {} 
before open source era: Eviews;

\item {} 
if I had more time: Julia.

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|*{2}{\X{1}{2}|}}
\hline
\sphinxstyletheadfamily 
Open source
&\sphinxstyletheadfamily 
Proprietary
\\
\hline\begin{itemize}
\item {} 
R (RStudio), derived from S

\item {} 
Python (Anaconda)

\item {} 
Julia

\end{itemize}
&\\
\hline\begin{itemize}
\item {} 
gretl

\end{itemize}
&\begin{itemize}
\item {} 
EViews (derived from TSP)

\end{itemize}
\\
\hline\begin{itemize}
\item {} 
Octave

\end{itemize}
&\begin{itemize}
\item {} 
MATLAB

\end{itemize}
\\
\hline&\begin{itemize}
\item {} 
SAS

\item {} 
SPSS

\item {} 
Stata

\end{itemize}
\\
\hline&
RATS, Ox, PcGive
\\
\hline
Stan, PyMC3, Turing.jl
&\\
\hline
\sphinxhref{https://www.jasp-stats.org}{JASP}
&\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\section{SAS and terminology}
\label{\detokenize{software:sas-and-terminology}}\begin{quote}

SAS, it seems, has become the gold standard, the output of SAS
programs the ultimate point of reference for correct and appropriate
statistical calculations and the SAS terminology israpidly taking
over as standard terminology. This is very Microsoft-like indeed and
very worrying for anyone who cares about the profession.
\end{quote}

\sphinxhref{https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf}{WN Venables. Exegeses on Linear
Models} - on early
adoption of S Plus


\section{Example: software used in black hole discovery}
\label{\detokenize{software:example-software-used-in-black-hole-discovery}}
Reading \sphinxstyleemphasis{First M87 Event Horizon Telescope Results. III. Data Processing and Calibration}:




\chapter{Good clues from Twitter}
\label{\detokenize{tweets:good-clues-from-twitter}}\label{\detokenize{tweets::doc}}
A secret subtitle for this publication is \sphinxstyleemphasis{“Can you learn econometrics from Twitter and Stack Overflow alone without distracting yourself to data science tutorials”}.

Links collcted in no particular order, some will show in other sections of the Navigator.


\section{No links between leading macrotextbooks}
\label{\detokenize{tweets:no-links-between-leading-macrotextbooks}}



\section{OLS interactively exposed}
\label{\detokenize{tweets:ols-interactively-exposed}}



\section{R language guide is an econometrics guide}
\label{\detokenize{tweets:r-language-guide-is-an-econometrics-guide}}



\section{OLS, MML, Bayes and MCMC(!) for linear regression}
\label{\detokenize{tweets:ols-mml-bayes-and-mcmc-for-linear-regression}}
\sphinxurl{https://peterroelants.github.io/posts/linear-regression-four-ways/}


\section{Very true on R2}
\label{\detokenize{tweets:very-true-on-r2}}



\section{Instrumental variables}
\label{\detokenize{tweets:instrumental-variables}}



\section{Interpreting coefficients 1}
\label{\detokenize{tweets:interpreting-coefficients-1}}



\section{Interpreting coefficients 2}
\label{\detokenize{tweets:interpreting-coefficients-2}}



\section{Doing PCA approach}
\label{\detokenize{tweets:doing-pca-approach}}



\section{OLS explained for social scientists}
\label{\detokenize{tweets:ols-explained-for-social-scientists}}



\section{Suggested stat excercises}
\label{\detokenize{tweets:suggested-stat-excercises}}



\section{Coding a tree}
\label{\detokenize{tweets:coding-a-tree}}



\section{Consumer demand modelling}
\label{\detokenize{tweets:consumer-demand-modelling}}



\section{Scott Cameron learning method}
\label{\detokenize{tweets:scott-cameron-learning-method}}



\section{Model evaluation compendium (on classifier)}
\label{\detokenize{tweets:model-evaluation-compendium-on-classifier}}



\section{Causality by Judea Pearl}
\label{\detokenize{tweets:causality-by-judea-pearl}}



\section{A thesis turned tutorial on probabilistic programming and MC inference by Tom Rainforth}
\label{\detokenize{tweets:a-thesis-turned-tutorial-on-probabilistic-programming-and-mc-inference-by-tom-rainforth}}



\section{Value of logit}
\label{\detokenize{tweets:value-of-logit}}



\section{Traditional statistics vs ML}
\label{\detokenize{tweets:traditional-statistics-vs-ml}}



\section{Program evaluation by John Holbein}
\label{\detokenize{tweets:program-evaluation-by-john-holbein}}



\section{218 pages on probabilistic programming}
\label{\detokenize{tweets:pages-on-probabilistic-programming}}



\section{A4 econometric art}
\label{\detokenize{tweets:a4-econometric-art}}



\section{A 1910 must-read}
\label{\detokenize{tweets:a-1910-must-read}}



\section{Amazing statistics animation}
\label{\detokenize{tweets:amazing-statistics-animation}}



\section{Undergrad econometrics condensed to 3 pages}
\label{\detokenize{tweets:undergrad-econometrics-condensed-to-3-pages}}
 


\chapter{Blogs}
\label{\detokenize{blogs:blogs}}\label{\detokenize{blogs::doc}}
Blogs may seem as an outdated fashion of communication, but they often present
a wider story than a twitter post.

Below there are some personal blogs that enlight and inspire about statistics and econometrics.
They are regularly updated.
\begin{itemize}
\item {} 
\sphinxhref{http://econometricsense.blogspot.com/}{Matt Bogard}

\item {} 
\sphinxhref{https://fxdiebold.blogspot.com/}{Francis Diebold}

\item {} 
\sphinxhref{https://davegiles.blogspot.com/}{Dave Giles}

\item {} 
\sphinxhref{https://robjhyndman.com/}{Rob Hyndman}

\end{itemize}

\sphinxhref{https://simplystatistics.org/}{Simply Statistics} by biostatistics
professors Rafa Irizarry, Roger Peng, and Jeff Leek cover data management,
analysis and teaching stats.

\sphinxhref{https://medium.com/tag/statistics}{Medium} has a variety of posts on statistics, but rarely tags econometrics. PCA is a widely popular topic.


\chapter{Acronyms}
\label{\detokenize{acronyms:acronyms}}\label{\detokenize{acronyms::doc}}
Econometrics is full of fancy abbreviations that one can juggle with.
\begin{description}
\item[{ANOVA\index{ANOVA@\spxentry{ANOVA}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-anova}}}] \leavevmode
analysis of variance

\item[{ARIMA\index{ARIMA@\spxentry{ARIMA}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-arima}}}] \leavevmode
autoregression, integration, moving average

\item[{DID\index{DID@\spxentry{DID}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-did}}}] \leavevmode
difference-in-differences

\item[{FE\index{FE@\spxentry{FE}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-fe}}}] \leavevmode
feature engineering

\item[{GARCH\index{GARCH@\spxentry{GARCH}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-garch}}}] \leavevmode
generalised (a)uto(r)egressive conditional heteroscedasticity

\item[{GLS\index{GLS@\spxentry{GLS}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-gls}}}] \leavevmode
generalised least squares

\item[{GMM\index{GMM@\spxentry{GMM}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-gmm}}}] \leavevmode
generalised method of moments

\item[{iid\index{iid@\spxentry{iid}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-iid}}}] \leavevmode
independent identicaly distributed

\item[{IV\index{IV@\spxentry{IV}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-iv}}}] \leavevmode
instrumental variable

\item[{OLS\index{OLS@\spxentry{OLS}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-ols}}}] \leavevmode
ordinary least squares

\item[{PCA\index{PCA@\spxentry{PCA}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-pca}}}] \leavevmode
principal components analysis

\item[{RDD\index{RDD@\spxentry{RDD}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-rdd}}}] \leavevmode
regression discontinuity design

\item[{VECM\index{VECM@\spxentry{VECM}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-vecm}}}] \leavevmode
vector error correction model

\item[{WLS\index{WLS@\spxentry{WLS}|spxpagem}\phantomsection\label{\detokenize{acronyms:term-wls}}}] \leavevmode
weighted least squares

\end{description}


\chapter{Changelog}
\label{\detokenize{roadmap:changelog}}\label{\detokenize{roadmap::doc}}
\sphinxstylestrong{v.0.0.5 (November 2019)}:
\begin{itemize}
\item {} 
new TOC and flatter stucture

\item {} 
generated a \sphinxhref{https://github.com/epogrebnyak/econometrics-navigator/blob/master/latex/EconometricsNavigator.pdf}{rough
pdf}

\item {} 
minimised errors for sphinx builds

\item {} 
tasks.py for invoke renewed

\end{itemize}

\sphinxstylestrong{v.0.0.4 (May 2019)}:
\begin{itemize}
\item {} 
Science of teaching: quoting @gvwilson, @nickchk, @AllenDowney, @RochelleTerman at \sphinxurl{https://tinyurl.com/em-nav-teach}

\item {} 
Data: added data from @stlouisfed/@quandl/@DBnomics along with several R data sources by @nickchk at \sphinxurl{https://tinyurl.com/em-nav-da}

\item {} 
Books:
\begin{itemize}
\item {} 
\sphinxhref{software.html\#sas-and-terminology}{WM Venables. Exegeses on Linear Models}

\item {} 
Walpole, Myers, Myers, Ye. Probability and Statistics for Engineers and Scientists

\end{itemize}

\end{itemize}

\sphinxstylestrong{v.0.0.3 (April 2019)} scraps several unfinished articles, including
a section on applications (hard to fill it quickly). Three main parts
in content established (own articles, textbook annotations and how to
teach resources).

\sphinxstylestrong{v.0.0.2 (November 2018)} original version of EN nobody understood what it is good for,
had sample articles on max likelihood, bootstrap, ANOVA.


\section{Roadmap}
\label{\detokenize{roadmap:roadmap}}

\section{November 09, 2019}
\label{\detokenize{roadmap:november-09-2019}}\begin{itemize}
\item {} 
drafts for cases and excercises

\item {} 
add more tweets

\item {} 
add from twitter personalities - links to them

\item {} 
Section 4 History may go somewhere else

\item {} 
logit models, tweets about them

\item {} 
add presentation about reproducibility

\item {} 
Statistical inference section is still a draft

\end{itemize}


\section{May 13, 2019}
\label{\detokenize{roadmap:may-13-2019}}

\subsection{General}
\label{\detokenize{roadmap:general}}\begin{itemize}
\item {} 
draw a mindmap for econometrics (as described in text)

\item {} 
put key textbooks on a roadmap

\item {} 
pay more attention to bayesian / causality

\end{itemize}


\subsection{Data science textbooks}
\label{\detokenize{roadmap:data-science-textbooks}}\begin{itemize}
\item {} 
\sphinxhref{https://github.com/tyleransom/DScourseS18}{Data Science fo Economists}

\end{itemize}


\subsection{Articles and code}
\label{\detokenize{roadmap:articles-and-code}}\begin{itemize}
\item {} 
write more articles and code for the main section

\item {} 
translate some RATS/MATLAB code to open source (especially time series)

\end{itemize}

Specific tasks:
\begin{itemize}
\item {} 
clean ols

\item {} 
run pca example

\end{itemize}


\subsection{Reproducibility}
\label{\detokenize{roadmap:reproducibility}}
Add resources on reproducible research and why it has such a poor traction in economics
\begin{itemize}
\item {} 
\sphinxhref{https://github.com/epogrebnyak/notes-pandoc/blob/master/paper.md}{this - 1}

\item {} 
\sphinxhref{https://github.com/epogrebnyak/notes-pandoc}{this - 2}

\end{itemize}

DAG tools:
\begin{itemize}
\item {} 
waf.io

\item {} 
invoke

\end{itemize}


\subsection{How to publish a textbook}
\label{\detokenize{roadmap:how-to-publish-a-textbook}}
Need an opensource textbook with interactive code examples, translation into Russian desired.
Hard to see a combination of a static site generator, good theme and PDf export working smoothly.
\begin{itemize}
\item {} 
Allen Downey on Medium

\item {} 
jupyter-book

\item {} 
bookdown

\end{itemize}


\subsection{Our publishing process}
\label{\detokenize{roadmap:our-publishing-process}}\begin{itemize}
\item {} 
things mentioned in \sphinxhref{https://github.com/epogrebnyak/econometrics-navigator/blob/master/todo.txt}{todo.txt}

\end{itemize}


\subsection{Other goals}
\label{\detokenize{roadmap:other-goals}}\begin{itemize}
\item {} 
review ‘depreciated’ folder, and ‘history’ page

\item {} 
‘vednorize’ \sphinxhref{https://github.com/epogrebnyak/LessOLS.jl}{LessOLS.jl}

\end{itemize}


\chapter{Welcome to Econometrics Navigator!}
\label{\detokenize{index:welcome-to-econometrics-navigator}}

\section{Goals}
\label{\detokenize{index:goals}}
The Econometrics Navigator (EN) goal is to make quality instruction in
statictics and econometrics accessible.

Let’s lower the barrier for entry and prevent gate-keeping!


\section{Types of content}
\label{\detokenize{index:types-of-content}}
We aim to provide you with:
\begin{itemize}
\item {} 
open access textbooks and community knowledge (reddit,
StackOverflow, Twitter threads),

\item {} 
minimal code examples in Python, R, gretl or Julia,

\item {} 
datasets and cases for quantative analysis,

\item {} 
ideas on how to structure your learning paths.

\end{itemize}


\subsection{1. Own articles}
\label{\detokenize{index:own-articles}}
The articles are in \sphinxhref{topics/index.rst}{Concepts and techniques section},
organised alphabetically. Finished examples are:
\begin{itemize}
\item {} 
\sphinxhref{topics/max-likelihood.html}{Maximum likelihood}

\item {} 
\sphinxhref{topics/bootstrap.html}{Bootstrap}

\item {} 
\sphinxhref{topics/anova.html}{ANOVA}

\end{itemize}


\subsection{2. Textbooks guide}
\label{\detokenize{index:textbooks-guide}}
\sphinxhref{textbook/index.html}{Textbooks review} attempts to sort out and annotate textbooks and
references by several categories, starting from math preliminaries and up to ML/DL
applications.

In econometrics the categories are ‘general’ textbooks, cross-section/panel, time series
and bayesian texts. Whatever I could not document well, I did put in the
\sphinxhref{textbook/mindmap.html}{mindmap} section.

The backstage workings of the Navigator are \sphinxhref{textbook/history.html}{History of econometrics},
\sphinxhref{textbook/ways-into-econometrics.html}{Ways to review econometrics}.

Review of resources about mathematic statistics are still a \sphinxhref{textbook/statistics.html}{draft}.


\subsection{3. Better teaching}
\label{\detokenize{index:better-teaching}}
These documents organise thinking about better teaching of
econometrics in terms of sequence of topics, better analogies
for the learner and a faster bridge to coding and working
with real data from formulas and concepts. Specifically I collected
the links about \sphinxhref{textbook/how-to-teach.html}{technical pedagogy here}.


\section{Twitter}
\label{\detokenize{index:twitter}}
So far twitter has been an enormously valuable source of demos, links and opinion for me.
I keep a \sphinxhref{tweets.html}{separate page with twitter posts}, some of my favorites are:
\begin{itemize}
\item {} 
\sphinxhref{https://twitter.com/tyleransom/status/1085242403643183105}{Undergrad Econometrics Cheatsheet} by Tyler Ransom

\end{itemize}


\begin{itemize}
\item {} 
\sphinxhref{http://nickchk.com/causalgraphs.html}{Casual graphs and XY plane animations} by Nick Huntington-Klein

\end{itemize}


\begin{itemize}
\item {} 
\sphinxhref{https://twitter.com/PogrebnyakE/status/1111897245362909185}{Investigative time series example} by @cubic\_logic

\end{itemize}


\begin{itemize}
\item {} 
\sphinxhref{https://lindeloev.github.io/tests-as-linear}{Common statistical tests are linear models (or: how to teach stats)} by Jonas Kristoffer Lindeløv

\end{itemize}




\section{Changelog}
\label{\detokenize{index:changelog}}
Changelog and future steps outlined are outlined in \sphinxhref{roadmap.html}{roadmap}.


\section{Contacts}
\label{\detokenize{index:contacts}}
This publication is edited by \sphinxhref{https://twitter.com/PogrebnyakE}{@PogrebnyakE}.


\section{Source}
\label{\detokenize{index:source}}
The source of this publication is available at \sphinxurl{https://github.com/epogrebnyak/econometrics-navigator}
and the short URL for this page is \sphinxurl{https://tinyurl.com/emnavig}.



\renewcommand{\indexname}{Index}
\printindex
\end{document}
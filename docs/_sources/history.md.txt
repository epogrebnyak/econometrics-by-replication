3.  History of econometrics
===========================

## Landmark events

- [Galton](http://jse.amstat.org/v9n3/stanton.html) and Pearson 
- Tinbergen, Haavelmo
- Cowles Commission
- Lucas critique


## Overviews

- [Econometrics: A Bird's Eye View](http://ftp.iza.org/dp2458.pdf)
- [Econometrics: An Historical Guide for the Uninitiated](https://www.le.ac.uk/economics/research/RePEc/lec/leecon/dp14-05.pdf)
- [The First Fifty Years of Modern Econometrics](https://www.researchgate.net/publication/24119912_The_First_Fifty_Years_of_Modern_Econometrics)


## By topic

- [timeless Cramer, 1946, Russian translation](http://cyber.sibsutis.ru:82/Monarev/docs/nauka/MV_Probability/MVsa_Statistics%20and%20applications/0417.Kramer-Matem_Metodi_Statistiki.pdf)

- [Pearl, J. (2014). Tygve Haavelmo and the emergence of causal calculus. Econometric Theory, 31(1), 152–179. https://doi.org/10.1017/s0266466614000231](ucla.in/2mhxKdO) 

- [A Short History of Markov Chain Monte Carlo (arxiv)](https://arxiv.org/pdf/0808.2902.pdf)

- [Working on 1960s macroeconometrics (blog)](https://beatricecherrier.wordpress.com/2018/10/15/working-on-1960s-macroeconometrics-theres-an-echo-on-the-line)

- [Criticizing the Lucas Critique: Macroeconometricians' Response to Robert Lucas](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2837766)

### Frequentist vs bayesian views on maximum likelihood

Source: [Florian Hartig](https://twitter.com/florianhartig)
answer on [Stack Overflow](https://stats.stackexchange.com/questions/180420/why-is-maximum-likelihood-estimation-considered-to-be-a-frequentist-technique/190695#190695)

Not all of these ideas were already present in Fisher's foundational 1922 paper ["On the mathematical foundations of theoretical statistics"](http://l.academicdirect.org/Horticulture/GAs/Refs/Fisher_1922_Estimation.pdf), but the idea of optimality and unbiasedness is, and Neyman latter added the idea of constructing CIs with fixed error rates. [Efron, 2013, "A 250-year argument: Belief, behavior, and the bootstrap"](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.306.4592&rep=rep1&type=pdf), summarizes in his very readable history of the Bayesian/Frequentist debate:

> The frequentist bandwagon really got rolling in the early 1900s. Ronald Fisher developed the maximum likelihood theory of optimal estimation, showing the best possible behavior for an estimate, and Jerzy Neyman did the same for confidence intervals and tests. Fisher’s and Neyman’s procedures were an almost perfect fit to the scientific needs and the computational limits of twentieth century science, casting Bayesianism into a shadow existence.

Notes:

- Fisher paper has vocabulary attached at the start of the article. 
- Efron papaer has a map with tiny AI space and comparison chart for 
  freq vs bayes methods.   